{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>debtinc</th>\n",
       "      <th>creddebt</th>\n",
       "      <th>othdebt</th>\n",
       "      <th>default</th>\n",
       "      <th>preddef1</th>\n",
       "      <th>preddef2</th>\n",
       "      <th>preddef3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>176</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.359392</td>\n",
       "      <td>5.008608</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808394</td>\n",
       "      <td>0.788640</td>\n",
       "      <td>0.213043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.362202</td>\n",
       "      <td>4.000798</td>\n",
       "      <td>0</td>\n",
       "      <td>0.198297</td>\n",
       "      <td>0.128445</td>\n",
       "      <td>0.436903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>2.168925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.141023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>120</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.658720</td>\n",
       "      <td>0.821280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.104422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.787436</td>\n",
       "      <td>3.056564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781588</td>\n",
       "      <td>0.737885</td>\n",
       "      <td>0.436903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  ed  employ  address  income  debtinc   creddebt   othdebt default  \\\n",
       "0   41   3      17       12     176      9.3  11.359392  5.008608       1   \n",
       "1   27   1      10        6      31     17.3   1.362202  4.000798       0   \n",
       "2   40   1      15       14      55      5.5   0.856075  2.168925       0   \n",
       "3   41   1      15       14     120      2.9   2.658720  0.821280       0   \n",
       "4   24   2       2        0      28     17.3   1.787436  3.056564       1   \n",
       "\n",
       "   preddef1  preddef2  preddef3  \n",
       "0  0.808394  0.788640  0.213043  \n",
       "1  0.198297  0.128445  0.436903  \n",
       "2  0.010036  0.002987  0.141023  \n",
       "3  0.022138  0.010273  0.104422  \n",
       "4  0.781588  0.737885  0.436903  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('bankloanData.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make a numpy array from the dataframe, except remove rows with no value for 'default'\n",
    "i = list(df1.columns.values).index('default')\n",
    "data = np.array([x for x in df1.values if x[i] in ['0', '1']])\n",
    "\n",
    "# Remove the columns for preddef1, predef2 and preddef3\n",
    "data = np.delete(data, slice(9,12), axis=1)\n",
    "\n",
    "# Separate the 'predictors' (aka 'features') from the dependent variable (aka 'label') \n",
    "# that we will learn how to predict\n",
    "predictors = np.delete(data, 8, axis=1)\n",
    "dependent = np.delete(data, slice(0, 8), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the label type to numeric categorical representing the classes to predict (binary classfier)\n",
    "dependent = dependent.astype(int)\n",
    "\n",
    "# And flatten it to one dimensional for use as the expected output label vector in TensorFlow\n",
    "dependent = dependent.flatten()\n",
    "\n",
    "# Convert all the predictors to float to simplify this demo TensorFlow code\n",
    "predictors = predictors.astype(float)\n",
    "\n",
    "# Get the shape of the predictors\n",
    "m, n = predictors.shape\n",
    "m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Partition the input data into a training set and a test set\n",
    "\n",
    "m_train = 500\n",
    "m_test = m - m_train\n",
    "\n",
    "predictors_train = predictors[:m_train]\n",
    "dependent_train = dependent[:m_train]\n",
    "\n",
    "predictors_test = predictors[m_train:]\n",
    "dependent_test = dependent[m_train:]\n",
    "\n",
    "# Gets a batch of the training data. \n",
    "# NOTE: Rather than loading a whole large data set as above and then taking array slices as done here, \n",
    "#       This method can connect to a data source and select just the batch needed.\n",
    "def get_training_batch(batch_num, batch_size):\n",
    "    lower = batch_num * (m_train // batch_size)\n",
    "    upper = lower + batch_size\n",
    "    return predictors_train[lower:upper], dependent_train[lower:upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Make this notebook's output stable across runs\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# A method to build a new neural net layer of a given size,  \n",
    "# fully connect it to a given preceding layer X, and \n",
    "# compute its output Z either with or without (default) an activation function\n",
    "# Call with activation=tf.nn.relu or tf.nn.sigmoid or tf.nn.tanh, for examples\n",
    "\n",
    "def make_nn_layer(layer_name, layer_size, X, activation=None):\n",
    "    with tf.name_scope(layer_name):\n",
    "        X_size = int(X.get_shape()[1])\n",
    "        SD = 2 / np.sqrt(X_size)\n",
    "        weights = tf.truncated_normal((X_size, layer_size), dtype=tf.float64, stddev=SD)\n",
    "        W = tf.Variable(weights, name='weights')\n",
    "        b = tf.Variable(tf.zeros([layer_size], dtype=tf.float64), name='biases')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        #Z = tf.add(tf.matmul(X, W), b, name=layer_name)\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the neural net structure\n",
    "\n",
    "n_inputs = n\n",
    "n_hidden1 = n \n",
    "### n_hidden2 = n // 2\n",
    "n_outputs = 2   # Two output classes: defaulting or non-defaulting on loan\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=(None, n_inputs), name='X')\n",
    "\n",
    "with tf.name_scope('nn'):\n",
    "    hidden1 = make_nn_layer('hidden1', n_hidden1, X, activation=tf.nn.relu)\n",
    "    hidden2 = hidden1\n",
    "    ### hidden2 = make_nn_layer('hidden2', n_hidden2, hidden1, activation=tf.nn.relu)\n",
    "    outputs = make_nn_layer('outputs', n_outputs, hidden2) \n",
    "    outputs = tf.identity(outputs, \"nn_output\")\n",
    "    \n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define how the neural net will learn\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=outputs)\n",
    "    loss = tf.reduce_mean(xentropy, name='l')\n",
    "    \n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"test\"):\n",
    "    correct = tf.nn.in_top_k(tf.cast(outputs, tf.float32), y, 1)\n",
    "    accuracy = tf.identity(tf.reduce_mean(tf.cast(correct, tf.float32)), \"accuracy\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subdirectory in which to save the model (only need to run this once)\n",
    "!mkdir \"../datasets/Neural Net2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 'Training accuracy:', 0.75999999, 'Testing accuracy:', 0.755)\n",
      "(200, 'Training accuracy:', 0.77399999, 'Testing accuracy:', 0.79000002)\n",
      "(300, 'Training accuracy:', 0.79799998, 'Testing accuracy:', 0.81999999)\n",
      "(400, 'Training accuracy:', 0.79799998, 'Testing accuracy:', 0.83499998)\n",
      "(500, 'Training accuracy:', 0.80800003, 'Testing accuracy:', 0.82499999)\n",
      "(500, ' training progress saved to ', '../datasets/Neural Net2/Neural Net.ckpt-500')\n",
      "(600, 'Training accuracy:', 0.796, 'Testing accuracy:', 0.815)\n",
      "(700, 'Training accuracy:', 0.80199999, 'Testing accuracy:', 0.81)\n",
      "(800, 'Training accuracy:', 0.78799999, 'Testing accuracy:', 0.815)\n",
      "(900, 'Training accuracy:', 0.81, 'Testing accuracy:', 0.815)\n",
      "(1000, 'Training accuracy:', 0.81999999, 'Testing accuracy:', 0.81)\n",
      "(1000, ' training progress saved to ', '../datasets/Neural Net2/Neural Net.ckpt-1000')\n",
      "(1100, 'Training accuracy:', 0.81800002, 'Testing accuracy:', 0.81)\n",
      "(1200, 'Training accuracy:', 0.80599999, 'Testing accuracy:', 0.80500001)\n",
      "(1300, 'Training accuracy:', 0.80199999, 'Testing accuracy:', 0.815)\n",
      "(1400, 'Training accuracy:', 0.81199998, 'Testing accuracy:', 0.81999999)\n",
      "(1500, 'Training accuracy:', 0.80599999, 'Testing accuracy:', 0.80000001)\n",
      "(1500, ' training progress saved to ', '../datasets/Neural Net2/Neural Net.ckpt-1500')\n"
     ]
    }
   ],
   "source": [
    "# We're going to model training disruption by manually doing half the \n",
    "# training in this cell, and then in the next cell we'll use a \n",
    "# new session, pick up where we left off, and ultimately get the\n",
    "# same answers as in cell [9].\n",
    "# Start by running cells [1] to [8], and then jump here rather than\n",
    "# doing cell [9]. (Run the mkdir above, if first time)\n",
    "\n",
    "# Set up the ability to save and restore the trained neural net\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# This is how many times to use the full set of training data\n",
    "# n_epochs = 3000\n",
    "n_epochs = 1500\n",
    "\n",
    "# For a larger training set, it's typically necessary to break training into\n",
    "# batches so only the memory needed to store one batch of training data is used\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as training_session:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Shuffling (across batches) is feasible for small data sets and\n",
    "        # helps increase accuracy of models trained with them\n",
    "        training_set = [[pt_elem, dependent_train[i]] for i, pt_elem in enumerate(predictors_train)]\n",
    "        np.random.shuffle(training_set)\n",
    "        predictors_train = [ts_elem[0] for ts_elem in training_set]\n",
    "        dependent_train = [ts_elem[1] for ts_elem in training_set]\n",
    "        \n",
    "        # Loop through the whole training set in batches\n",
    "        for batch_num in range(m_train // batch_size):\n",
    "            X_batch, y_batch = get_training_batch(batch_num, batch_size)\n",
    "            training_session.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "        if epoch % 100 == 99:\n",
    "            acc_train = accuracy.eval(feed_dict={X: predictors_train, y: dependent_train})\n",
    "            acc_test = accuracy.eval(feed_dict={X: predictors_test, y: dependent_test})\n",
    "            print(epoch+1, \"Training accuracy:\", acc_train, \"Testing accuracy:\", acc_test)\n",
    "            \n",
    "        if (epoch % 500) == 499:\n",
    "            save_path = saver.save(training_session, \"../datasets/Neural Net2/Neural Net.ckpt\", global_step=epoch+1)\n",
    "            print(epoch+1, \" training progress saved to \", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../datasets/Neural Net2/Neural Net.ckpt-1500\n",
      "(1600, 'Training accuracy:', 0.81599998, 'Testing accuracy:', 0.81)\n",
      "(1700, 'Training accuracy:', 0.80599999, 'Testing accuracy:', 0.81)\n",
      "(1800, 'Training accuracy:', 0.82200003, 'Testing accuracy:', 0.82499999)\n",
      "(1900, 'Training accuracy:', 0.80199999, 'Testing accuracy:', 0.80500001)\n",
      "(2000, 'Training accuracy:', 0.82999998, 'Testing accuracy:', 0.81999999)\n",
      "(2000, ' training progress saved to ', '../datasets/Neural Net2/Neural Net.ckpt-2000')\n",
      "(2100, 'Training accuracy:', 0.81199998, 'Testing accuracy:', 0.81)\n",
      "(2200, 'Training accuracy:', 0.824, 'Testing accuracy:', 0.82499999)\n",
      "(2300, 'Training accuracy:', 0.80400002, 'Testing accuracy:', 0.815)\n",
      "(2400, 'Training accuracy:', 0.81800002, 'Testing accuracy:', 0.815)\n",
      "(2500, 'Training accuracy:', 0.82800001, 'Testing accuracy:', 0.82499999)\n",
      "(2500, ' training progress saved to ', '../datasets/Neural Net2/Neural Net.ckpt-2500')\n",
      "(2600, 'Training accuracy:', 0.82999998, 'Testing accuracy:', 0.815)\n",
      "(2700, 'Training accuracy:', 0.82200003, 'Testing accuracy:', 0.815)\n",
      "(2800, 'Training accuracy:', 0.81999999, 'Testing accuracy:', 0.80500001)\n",
      "(2900, 'Training accuracy:', 0.81400001, 'Testing accuracy:', 0.82999998)\n",
      "(3000, 'Training accuracy:', 0.82599998, 'Testing accuracy:', 0.82499999)\n",
      "(3000, ' training progress saved to ', '../datasets/Neural Net2/Neural Net.ckpt-3000')\n",
      "\n",
      "('Actual classes:   ', array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))\n",
      "('Predicted classes:', array([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "# IT IS NOT NECESSARY, BUT YOU CAN RESTART THE KERNEL NOW, THEN RUN CELLS [1] through [4], \n",
    "# THEN RUN THIS CELL.\n",
    "# THE ONLY DIFFERENCE IS THAT THE RANDOM NUMBER GENERATORS WILL NOT BE PRESERVED, SO\n",
    "# ACCURACY WILL COME OUT SLIGHTLY DIFFERENTLY DUE TO DIFFERENCES IN BATCH RANDOMIZATION\n",
    "\n",
    "import tensorflow as tf_training2\n",
    "\n",
    "# Make this notebook's randomization consisoutput stable across runs\n",
    "tf_training2.reset_default_graph()\n",
    "\n",
    "# This is how many times to use the full set of training data\n",
    "n_epochs = 3000\n",
    "\n",
    "# For a larger training set, it's typically necessary to break training into\n",
    "# batches so only the memory needed to store one batch of training data is used\n",
    "batch_size = 50\n",
    "\n",
    "with tf_training2.Session() as training2_session:\n",
    "    # Initialize by restoring the model, as we did for inference, except from a specific checkpoint file\n",
    "    inf_saver = tf_training2.train.import_meta_graph('../datasets/Neural Net2/Neural Net.ckpt-1500.meta')\n",
    "    inf_saver.restore(training2_session, tf_training2.train.latest_checkpoint('../datasets/Neural Net2/'))\n",
    "    \n",
    "    # We have a few more variables to get now that we have to resume training and not just do inference\n",
    "    # but we use essentially the same methods\n",
    "    graph = tf_training2.get_default_graph()    \n",
    "    training2_op = graph.get_operation_by_name(\"train/GradientDescent\")\n",
    "    X2 = graph.get_tensor_by_name(\"X:0\")\n",
    "    y2 = graph.get_tensor_by_name(\"y:0\")\n",
    "    accuracy2 = graph.get_tensor_by_name(\"test/accuracy:0\")\n",
    "    outputs2 = graph.get_tensor_by_name(\"nn/nn_output:0\")\n",
    "    \n",
    "    # And now we make a new saver so we can keep on saving\n",
    "    saver2 = tf_training2.train.Saver()\n",
    "    \n",
    "    for epoch in range(1500, n_epochs):\n",
    "        \n",
    "        # Shuffling (across batches) is feasible for small data sets and\n",
    "        # helps increase accuracy of models trained with them\n",
    "        training_set = [[pt_elem, dependent_train[i]] for i, pt_elem in enumerate(predictors_train)]\n",
    "        np.random.shuffle(training_set)\n",
    "        predictors_train = [ts_elem[0] for ts_elem in training_set]\n",
    "        dependent_train = [ts_elem[1] for ts_elem in training_set]\n",
    "        \n",
    "        # Loop through the whole training set in batches\n",
    "        for batch_num in range(m_train // batch_size):\n",
    "            X_batch, y_batch = get_training_batch(batch_num, batch_size)\n",
    "            training2_session.run(training2_op, feed_dict={X2: X_batch, y2: y_batch})\n",
    "\n",
    "        if epoch % 100 == 99:\n",
    "            acc_train = accuracy2.eval(feed_dict={X2: predictors_train, y2: dependent_train})\n",
    "            acc_test = accuracy2.eval(feed_dict={X2: predictors_test, y2: dependent_test})\n",
    "            print(epoch+1, \"Training accuracy:\", acc_train, \"Testing accuracy:\", acc_test)\n",
    "            \n",
    "        if (epoch % 500) == 499:\n",
    "            save_path = saver2.save(training2_session, \"../datasets/Neural Net2/Neural Net.ckpt\", global_step=epoch+1)\n",
    "            print(epoch+1, \" training progress saved to \", save_path)\n",
    "\n",
    "    save_path = saver2.save(training2_session, \"../datasets/Neural Net2/Neural Net.ckpt\")\n",
    "    \n",
    "    # A quick test with the trained model \n",
    "    Z = outputs2.eval(feed_dict={X2: predictors_test[:20]})\n",
    "    dependent_pred = np.argmax(Z, axis=1)\n",
    "    print(\"\")\n",
    "    print(\"Actual classes:   \", dependent_test[:20])  \n",
    "    print(\"Predicted classes:\", dependent_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../datasets/Neural Net2/Neural Net.ckpt\n",
      "('Actual classes:   ', array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]))\n",
      "('Predicted classes:', array([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]))\n",
      "\n",
      "('Confidences: ', [0.52043336936529361, 0.60743242082144699, 0.90885995549847642, 0.82881417106871791, 0.64183287473507922, 0.64561868763996888, 0.99976562364001409, 0.94011937011564328, 0.53148089582746982, 0.9999981651739771, 0.64561868763996888, 0.93856761783910991, 0.90356160195413848, 0.87077192043544993, 0.95194737137632246, 0.89962254358045246, 0.99999948225363267, 0.91842834381999272, 0.9823504262210323, 0.91310968891675703, 0.72115788841227302, 0.80607047578305713, 0.83934041973914708, 0.99522251895376912, 0.63583707224033514, 0.92301370061024191, 0.9246727235093638, 0.78439759502501416, 0.99999999999583422, 0.64561868763996888, 0.72736408931601459, 0.64561868763996888, 0.83959328566375235, 0.94291801514712859, 0.68170960394665236, 0.99981345698850999, 0.96778595641239296, 0.59248611260528017, 0.99293831799558985, 0.52204835458766652, 0.97478120783557964, 0.93768743911327046, 0.99979011204691504, 0.94923722253390908, 0.99599830163375069, 0.98742439011891581, 0.76902849246046312, 0.99938012479901295, 0.83603848197518038, 0.9991935041637936, 0.60524199602146223, 0.64561868763996888, 0.90483194732194827, 0.99835400455605183, 0.99883681027092364, 0.89749562181323328, 0.92735034530347338, 0.9893738856985953, 0.70331613825333239, 0.72667848509732968, 0.97237330665498523, 0.93840734795981517, 0.99999999999999822, 0.97615378213330617, 0.99991411464354829, 0.62386214036786924, 0.97891232073379641, 0.99631814840383348, 0.64561868763996888, 0.99999603576001816, 0.64561868763996888, 0.60835114037415949, 0.99999999999993472, 0.73604389617214927, 0.64561868763996888, 0.56034506723475364, 0.87163767344179965, 0.99995080059946906, 0.57597911635214605, 0.95469784100409094, 0.67224015555636052, 0.91662280095533, 0.68169094273468145, 0.64561868763996888, 0.64561868763996888, 0.8882536897804324, 0.88414408138995637, 0.85762177932803718, 0.84098503588093942, 0.73874185513539892, 0.64561868763996888, 0.56399304408066475, 0.9187918170552668, 0.87306620785535516, 0.64561868763996888, 0.97770580720684341, 0.55909602460110686, 0.64561868763996888, 0.62495942308589991, 0.64561868763996888, 0.63227613412576444, 0.99999971496048756, 0.67052903566823774, 0.97512098718591522, 0.64561868763996888, 1.0, 0.64561868763996888, 0.80449365147556839, 0.75250570197523914, 0.82604523246475747, 0.71691171283160404, 0.95600450128150893, 0.56507795675385697, 0.99999999999999978, 0.93910230769810399, 0.99999573337676595, 0.5448487234130891, 0.90896612450962211, 0.51865891429846711, 0.64561868763996888, 0.53988302628213136, 0.90799157742937742, 1.0, 0.99332321732433582, 0.65864487470676125, 0.99999999941758255, 0.75372881294893113, 0.86682517595756725, 0.60290174020358678, 0.56089502080990739, 0.8384872671868393, 0.99529470346008664, 0.99930822822484433, 0.64561868763996888, 0.99999859094758536, 0.99999999999915579, 0.64561868763996888, 0.64561868763996888, 0.91276321427289853, 0.83688484543331321, 0.87047219354615613, 0.9984972459031165, 0.58206117443149152, 0.87317798625522436, 0.99986906371639295, 0.64561868763996888, 0.9593450128300034, 0.74501216780369028, 0.99154304440233976, 0.55445819646438499, 0.92083299413036424, 0.72605401132218284, 0.97353285551296087, 0.65499514446991736, 0.67264262654558826, 0.98887808902320506, 0.97931040971894567, 0.99879270359703276, 0.840854418539844, 0.78937262399116692, 0.69338625658483988, 0.81033717008137118, 0.87732289080657166, 0.95777775404352838, 0.99997237180138998, 0.99999999999952904, 0.99999999999914513, 0.77938185221091671, 0.95346819996733889, 0.88609640852618177, 0.67491421441458754, 0.53145008143605665, 0.90342512926519114, 0.64561868763996888, 0.80900305305163456, 0.99999999999999734, 0.78782567785510715, 0.91776022388878764, 0.89803498104204404, 0.99378611678460016, 0.52593833162307035, 0.6912965553732705, 0.83563733116758943, 0.54476042455036511, 0.99986354527087906, 0.56422640001367363, 0.62324520947107587, 0.68727856839775447, 0.99991908996387568, 0.74720468683731045, 0.62581756996104387, 0.99999938638642238, 0.64561868763996888, 0.56799850321937906, 0.64561868763996888, 0.95626950855223636, 0.8499310793365854, 0.98216712148898699, 0.99936034173165866, 0.81187030955740569])\n",
      "\n",
      "('Probabilities: ', array([[  4.79566631e-01,   5.20433369e-01],\n",
      "       [  3.92567579e-01,   6.07432421e-01],\n",
      "       [  9.11400445e-02,   9.08859955e-01],\n",
      "       [  8.28814171e-01,   1.71185829e-01],\n",
      "       [  3.58167125e-01,   6.41832875e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.99765624e-01,   2.34376360e-04],\n",
      "       [  9.40119370e-01,   5.98806299e-02],\n",
      "       [  5.31480896e-01,   4.68519104e-01],\n",
      "       [  9.99998165e-01,   1.83482602e-06],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.38567618e-01,   6.14323822e-02],\n",
      "       [  9.03561602e-01,   9.64383980e-02],\n",
      "       [  8.70771920e-01,   1.29228080e-01],\n",
      "       [  9.51947371e-01,   4.80526286e-02],\n",
      "       [  8.99622544e-01,   1.00377456e-01],\n",
      "       [  9.99999482e-01,   5.17746367e-07],\n",
      "       [  9.18428344e-01,   8.15716562e-02],\n",
      "       [  9.82350426e-01,   1.76495738e-02],\n",
      "       [  9.13109689e-01,   8.68903111e-02],\n",
      "       [  7.21157888e-01,   2.78842112e-01],\n",
      "       [  8.06070476e-01,   1.93929524e-01],\n",
      "       [  8.39340420e-01,   1.60659580e-01],\n",
      "       [  9.95222519e-01,   4.77748105e-03],\n",
      "       [  6.35837072e-01,   3.64162928e-01],\n",
      "       [  9.23013701e-01,   7.69862994e-02],\n",
      "       [  9.24672724e-01,   7.53272765e-02],\n",
      "       [  7.84397595e-01,   2.15602405e-01],\n",
      "       [  1.00000000e+00,   4.16586334e-12],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  7.27364089e-01,   2.72635911e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  8.39593286e-01,   1.60406714e-01],\n",
      "       [  9.42918015e-01,   5.70819849e-02],\n",
      "       [  6.81709604e-01,   3.18290396e-01],\n",
      "       [  9.99813457e-01,   1.86543011e-04],\n",
      "       [  9.67785956e-01,   3.22140436e-02],\n",
      "       [  4.07513887e-01,   5.92486113e-01],\n",
      "       [  9.92938318e-01,   7.06168200e-03],\n",
      "       [  4.77951645e-01,   5.22048355e-01],\n",
      "       [  9.74781208e-01,   2.52187922e-02],\n",
      "       [  9.37687439e-01,   6.23125609e-02],\n",
      "       [  9.99790112e-01,   2.09887953e-04],\n",
      "       [  5.07627775e-02,   9.49237223e-01],\n",
      "       [  9.95998302e-01,   4.00169837e-03],\n",
      "       [  9.87424390e-01,   1.25756099e-02],\n",
      "       [  7.69028492e-01,   2.30971508e-01],\n",
      "       [  6.19875201e-04,   9.99380125e-01],\n",
      "       [  8.36038482e-01,   1.63961518e-01],\n",
      "       [  8.06495836e-04,   9.99193504e-01],\n",
      "       [  6.05241996e-01,   3.94758004e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.04831947e-01,   9.51680527e-02],\n",
      "       [  9.98354005e-01,   1.64599544e-03],\n",
      "       [  9.98836810e-01,   1.16318973e-03],\n",
      "       [  8.97495622e-01,   1.02504378e-01],\n",
      "       [  9.27350345e-01,   7.26496547e-02],\n",
      "       [  1.06261143e-02,   9.89373886e-01],\n",
      "       [  7.03316138e-01,   2.96683862e-01],\n",
      "       [  7.26678485e-01,   2.73321515e-01],\n",
      "       [  9.72373307e-01,   2.76266933e-02],\n",
      "       [  9.38407348e-01,   6.15926520e-02],\n",
      "       [  1.00000000e+00,   1.68092054e-15],\n",
      "       [  9.76153782e-01,   2.38462179e-02],\n",
      "       [  8.58853565e-05,   9.99914115e-01],\n",
      "       [  6.23862140e-01,   3.76137860e-01],\n",
      "       [  9.78912321e-01,   2.10876793e-02],\n",
      "       [  9.96318148e-01,   3.68185160e-03],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.99996036e-01,   3.96423998e-06],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  6.08351140e-01,   3.91648860e-01],\n",
      "       [  1.00000000e+00,   6.52202564e-14],\n",
      "       [  7.36043896e-01,   2.63956104e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  4.39654933e-01,   5.60345067e-01],\n",
      "       [  8.71637673e-01,   1.28362327e-01],\n",
      "       [  9.99950801e-01,   4.91994005e-05],\n",
      "       [  5.75979116e-01,   4.24020884e-01],\n",
      "       [  9.54697841e-01,   4.53021590e-02],\n",
      "       [  6.72240156e-01,   3.27759844e-01],\n",
      "       [  9.16622801e-01,   8.33771990e-02],\n",
      "       [  6.81690943e-01,   3.18309057e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  8.88253690e-01,   1.11746310e-01],\n",
      "       [  8.84144081e-01,   1.15855919e-01],\n",
      "       [  8.57621779e-01,   1.42378221e-01],\n",
      "       [  8.40985036e-01,   1.59014964e-01],\n",
      "       [  7.38741855e-01,   2.61258145e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  4.36006956e-01,   5.63993044e-01],\n",
      "       [  9.18791817e-01,   8.12081829e-02],\n",
      "       [  8.73066208e-01,   1.26933792e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.77705807e-01,   2.22941928e-02],\n",
      "       [  5.59096025e-01,   4.40903975e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  6.24959423e-01,   3.75040577e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  6.32276134e-01,   3.67723866e-01],\n",
      "       [  9.99999715e-01,   2.85039513e-07],\n",
      "       [  6.70529036e-01,   3.29470964e-01],\n",
      "       [  9.75120987e-01,   2.48790128e-02],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  1.00000000e+00,   7.30460392e-17],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  8.04493651e-01,   1.95506349e-01],\n",
      "       [  7.52505702e-01,   2.47494298e-01],\n",
      "       [  8.26045232e-01,   1.73954768e-01],\n",
      "       [  7.16911713e-01,   2.83088287e-01],\n",
      "       [  9.56004501e-01,   4.39954987e-02],\n",
      "       [  4.34922043e-01,   5.65077957e-01],\n",
      "       [  1.00000000e+00,   1.62648001e-16],\n",
      "       [  9.39102308e-01,   6.08976923e-02],\n",
      "       [  9.99995733e-01,   4.26662323e-06],\n",
      "       [  5.44848723e-01,   4.55151277e-01],\n",
      "       [  9.08966125e-01,   9.10338755e-02],\n",
      "       [  4.81341086e-01,   5.18658914e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  5.39883026e-01,   4.60116974e-01],\n",
      "       [  9.07991577e-01,   9.20084226e-02],\n",
      "       [  1.00000000e+00,   8.26926694e-23],\n",
      "       [  9.93323217e-01,   6.67678268e-03],\n",
      "       [  6.58644875e-01,   3.41355125e-01],\n",
      "       [  9.99999999e-01,   5.82417500e-10],\n",
      "       [  7.53728813e-01,   2.46271187e-01],\n",
      "       [  8.66825176e-01,   1.33174824e-01],\n",
      "       [  3.97098260e-01,   6.02901740e-01],\n",
      "       [  4.39104979e-01,   5.60895021e-01],\n",
      "       [  8.38487267e-01,   1.61512733e-01],\n",
      "       [  9.95294703e-01,   4.70529654e-03],\n",
      "       [  6.91771775e-04,   9.99308228e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.99998591e-01,   1.40905241e-06],\n",
      "       [  1.00000000e+00,   8.44237762e-13],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.12763214e-01,   8.72367857e-02],\n",
      "       [  8.36884845e-01,   1.63115155e-01],\n",
      "       [  8.70472194e-01,   1.29527806e-01],\n",
      "       [  9.98497246e-01,   1.50275410e-03],\n",
      "       [  5.82061174e-01,   4.17938826e-01],\n",
      "       [  8.73177986e-01,   1.26822014e-01],\n",
      "       [  9.99869064e-01,   1.30936284e-04],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.59345013e-01,   4.06549872e-02],\n",
      "       [  7.45012168e-01,   2.54987832e-01],\n",
      "       [  9.91543044e-01,   8.45695560e-03],\n",
      "       [  4.45541804e-01,   5.54458196e-01],\n",
      "       [  9.20832994e-01,   7.91670059e-02],\n",
      "       [  7.26054011e-01,   2.73945989e-01],\n",
      "       [  9.73532856e-01,   2.64671445e-02],\n",
      "       [  6.54995144e-01,   3.45004856e-01],\n",
      "       [  6.72642627e-01,   3.27357373e-01],\n",
      "       [  9.88878089e-01,   1.11219110e-02],\n",
      "       [  9.79310410e-01,   2.06895903e-02],\n",
      "       [  9.98792704e-01,   1.20729640e-03],\n",
      "       [  8.40854419e-01,   1.59145581e-01],\n",
      "       [  7.89372624e-01,   2.10627376e-01],\n",
      "       [  6.93386257e-01,   3.06613743e-01],\n",
      "       [  8.10337170e-01,   1.89662830e-01],\n",
      "       [  8.77322891e-01,   1.22677109e-01],\n",
      "       [  9.57777754e-01,   4.22222460e-02],\n",
      "       [  9.99972372e-01,   2.76281986e-05],\n",
      "       [  1.00000000e+00,   4.71061254e-13],\n",
      "       [  1.00000000e+00,   8.54789930e-13],\n",
      "       [  7.79381852e-01,   2.20618148e-01],\n",
      "       [  9.53468200e-01,   4.65318000e-02],\n",
      "       [  8.86096409e-01,   1.13903591e-01],\n",
      "       [  6.74914214e-01,   3.25085786e-01],\n",
      "       [  4.68549919e-01,   5.31450081e-01],\n",
      "       [  9.03425129e-01,   9.65748707e-02],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  8.09003053e-01,   1.90996947e-01],\n",
      "       [  1.00000000e+00,   2.58034102e-15],\n",
      "       [  7.87825678e-01,   2.12174322e-01],\n",
      "       [  9.17760224e-01,   8.22397761e-02],\n",
      "       [  8.98034981e-01,   1.01965019e-01],\n",
      "       [  9.93786117e-01,   6.21388322e-03],\n",
      "       [  4.74061668e-01,   5.25938332e-01],\n",
      "       [  6.91296555e-01,   3.08703445e-01],\n",
      "       [  8.35637331e-01,   1.64362669e-01],\n",
      "       [  5.44760425e-01,   4.55239575e-01],\n",
      "       [  9.99863545e-01,   1.36454729e-04],\n",
      "       [  5.64226400e-01,   4.35773600e-01],\n",
      "       [  6.23245209e-01,   3.76754791e-01],\n",
      "       [  6.87278568e-01,   3.12721432e-01],\n",
      "       [  9.99919090e-01,   8.09100361e-05],\n",
      "       [  7.47204687e-01,   2.52795313e-01],\n",
      "       [  6.25817570e-01,   3.74182430e-01],\n",
      "       [  9.99999386e-01,   6.13613578e-07],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  5.67998503e-01,   4.32001497e-01],\n",
      "       [  3.54381312e-01,   6.45618688e-01],\n",
      "       [  9.56269509e-01,   4.37304914e-02],\n",
      "       [  8.49931079e-01,   1.50068921e-01],\n",
      "       [  9.82167121e-01,   1.78328785e-02],\n",
      "       [  9.99360342e-01,   6.39658268e-04],\n",
      "       [  8.11870310e-01,   1.88129690e-01]]))\n"
     ]
    }
   ],
   "source": [
    "# Restore the saved model and use it to perform inference on a \"received\" new set of data\n",
    "\n",
    "# We will simulate \"receiving\" the new data by taking a slice of the test set.\n",
    "#predictors_received = predictors_test[20:40]\n",
    "predictors_received = predictors_test[:]\n",
    "\n",
    "import tensorflow as tf_inference\n",
    "\n",
    "with tf_inference.Session() as inference_session:\n",
    "    inf_saver = tf_inference.train.import_meta_graph('../datasets/Neural Net2/Neural Net.ckpt.meta')\n",
    "    inf_saver.restore(inference_session, tf_inference.train.latest_checkpoint('../datasets/Neural Net2/'))\n",
    "    \n",
    "    graph = tf_inference.get_default_graph()\n",
    "    X = graph.get_tensor_by_name(\"X:0\")\n",
    "    nn_output = graph.get_tensor_by_name(\"nn/nn_output:0\")\n",
    "\n",
    "    Z = inference_session.run(nn_output, feed_dict={X: predictors_received})\n",
    "    dependent_pred = np.argmax(Z, axis=1)\n",
    "    \n",
    "    dependent_prob = inference_session.run(tf_inference.nn.softmax(nn_output), feed_dict={X: predictors_received})\n",
    "\n",
    "    confidences = [p[dependent_pred[i]] for i, p in enumerate(dependent_prob)]\n",
    "    \n",
    "print(\"Actual classes:   \", dependent_test[:])\n",
    "print(\"Predicted classes:\", dependent_pred)\n",
    "print(\"\")\n",
    "print(\"Confidences: \", confidences)\n",
    "print(\"\")\n",
    "print(\"Probabilities: \", dependent_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85273972602739723"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# send the actual dependent variable classifications for param 1, \n",
    "# and the confidences of the true classification for param 2\n",
    "FPR, TPR, _ = roc_curve(dependent_test, dependent_prob[:, 1])\n",
    "\n",
    "# Now calculate the area under the confidence ROC curve\n",
    "# This area is equated with the probability that the classifier will rank \n",
    "# a randomly selected defaulter higher than a randomly selected non-defaulter\n",
    "AUC = auc(FPR, TPR)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwemt1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the confidence ROC curve \n",
    "plt.figure()\n",
    "plt.plot(FPR, TPR, label='ROC curve (area = %0.2f)' % AUC)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10974d690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDeL/AdoIm9GbeaMhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install this, if necessary\n",
    "# !pip install --user --upgrade sklearn_evaluation\n",
    "\n",
    "from sklearn_evaluation import plot\n",
    "%matplotlib inline\n",
    "\n",
    "labels = [\"Non-defaulters\", \"Defaulters\"]\n",
    "\n",
    "plot.confusion_matrix(dependent_test, dependent_pred, target_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043730491447763684"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependent_test is the actual classifications\n",
    "# dependent_prob is the probabilities\n",
    "# The lowest confidence that can give 100% TPR on the test set is equal to the \n",
    "# true class with the lowest confidence, so we'll find that now\n",
    "\n",
    "defaulter_probs = [dependent_prob[i][1] for i, p in enumerate(dependent_test) if p == 1]\n",
    "min_conf = np.min(defaulter_probs)\n",
    "min_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each non-defaulter with a confidence at or above min_conf would be predicted \n",
    "# to be a defaulter (which would be a false positve prediction for a non-defaulter)\n",
    "\n",
    "non_defaulter_probs = [dependent_prob[i][1] for i, p in enumerate(dependent_test) if p == 0]\n",
    "false_positives = [x for x in non_defaulter_probs if x >= min_conf]\n",
    "\n",
    "total = len(defaulter_probs) + len(non_defaulter_probs)\n",
    "total_correct = total - len(false_positives)\n",
    "accuracy = float(total_correct) / total\n",
    "\n",
    "# Overall accuracy would suffer quite a bit, but this achieves \n",
    "# the desired high accuracy on true positive identification (defaulters)  \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For when you want to wipe out the training and do it again\n",
    "#!rm -rf \"../datasets/Neural Net\"\n",
    "# Commented out to avoid accidental execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 544\r\n",
      "-rw-r--r--  1 boyerj  staff    720 27 Apr 11:47 Neural Net.ckpt-1000.data-00000-of-00001\r\n",
      "-rw-r--r--  1 boyerj  staff    238 27 Apr 11:47 Neural Net.ckpt-1000.index\r\n",
      "-rw-r--r--  1 boyerj  staff  25821 27 Apr 11:47 Neural Net.ckpt-1000.meta\r\n",
      "-rw-r--r--  1 boyerj  staff    720 27 Apr 11:47 Neural Net.ckpt-1500.data-00000-of-00001\r\n",
      "-rw-r--r--  1 boyerj  staff    238 27 Apr 11:47 Neural Net.ckpt-1500.index\r\n",
      "-rw-r--r--  1 boyerj  staff  25821 27 Apr 11:47 Neural Net.ckpt-1500.meta\r\n",
      "-rw-r--r--  1 boyerj  staff    720 27 Apr 11:47 Neural Net.ckpt-2000.data-00000-of-00001\r\n",
      "-rw-r--r--  1 boyerj  staff    238 27 Apr 11:47 Neural Net.ckpt-2000.index\r\n",
      "-rw-r--r--  1 boyerj  staff  28892 27 Apr 11:47 Neural Net.ckpt-2000.meta\r\n",
      "-rw-r--r--  1 boyerj  staff    720 27 Apr 11:47 Neural Net.ckpt-2500.data-00000-of-00001\r\n",
      "-rw-r--r--  1 boyerj  staff    238 27 Apr 11:47 Neural Net.ckpt-2500.index\r\n",
      "-rw-r--r--  1 boyerj  staff  28892 27 Apr 11:47 Neural Net.ckpt-2500.meta\r\n",
      "-rw-r--r--  1 boyerj  staff    720 27 Apr 11:48 Neural Net.ckpt-3000.data-00000-of-00001\r\n",
      "-rw-r--r--  1 boyerj  staff    238 27 Apr 11:48 Neural Net.ckpt-3000.index\r\n",
      "-rw-r--r--  1 boyerj  staff  28892 27 Apr 11:48 Neural Net.ckpt-3000.meta\r\n",
      "-rw-r--r--  1 boyerj  staff    720 27 Apr 11:47 Neural Net.ckpt-500.data-00000-of-00001\r\n",
      "-rw-r--r--  1 boyerj  staff    238 27 Apr 11:47 Neural Net.ckpt-500.index\r\n",
      "-rw-r--r--  1 boyerj  staff  25821 27 Apr 11:47 Neural Net.ckpt-500.meta\r\n",
      "-rw-r--r--  1 boyerj  staff    720 27 Apr 11:48 Neural Net.ckpt.data-00000-of-00001\r\n",
      "-rw-r--r--  1 boyerj  staff    238 27 Apr 11:48 Neural Net.ckpt.index\r\n",
      "-rw-r--r--  1 boyerj  staff  28892 27 Apr 11:48 Neural Net.ckpt.meta\r\n",
      "-rw-r--r--  1 boyerj  staff    240 27 Apr 11:48 checkpoint\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l \"../datasets/Neural Net2\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
